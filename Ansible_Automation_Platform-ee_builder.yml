---
# Ansible Automation Platform - Execution Environment Builder
# This playbook builds customized execution environments based on Red Hat AAP base images

# Play 1: Verify or collect credentials
- name: Setup and store credentials
  hosts: localhost
  connection: local
  gather_facts: true
  tasks:
    # Clear screen as the very first action
    - name: Clear screen at playbook start
      ansible.builtin.shell: clear
      changed_when: false
      tags: [always]
      
    # Create basic ansible.cfg immediately as the first functional task
    - name: Create initial basic ansible.cfg file
      ansible.builtin.shell: |
        cat > ansible.cfg << 'EOF'
        [defaults]
        inventory = localhost,
        ansible_localhost_warning=false
        ansible_deprecation_warnings=false
        force_color = True

        [galaxy]
        server_list = validated, published, galaxy

        [galaxy_server.published]
        url=https://console.redhat.com/api/automation-hub/content/published/
        auth_url=https://sso.redhat.com/auth/realms/redhat-external/protocol/openid-connect/token

        [galaxy_server.validated]
        url=https://console.redhat.com/api/automation-hub/content/validated/
        auth_url=https://sso.redhat.com/auth/realms/redhat-external/protocol/openid-connect/token

        [galaxy_server.galaxy]
        url=https://galaxy.ansible.com/
        EOF
      args:
        chdir: "{{ playbook_dir }}"
        creates: "{{ playbook_dir }}/ansible.cfg"
      changed_when: true
      tags: [always]

    # Improved user detection logic
    - name: Get effective and real user info
      ansible.builtin.shell: |
        echo "EUID=$(id -u)"
        if [ -n "$SUDO_USER" ]; then
          echo "SUDO_USER=$SUDO_USER"
          echo "SUDO_UID=$(id -u $SUDO_USER)"
          echo "SUDO_HOME=$(eval echo ~$SUDO_USER)"
        else
          echo "SUDO_USER="
          echo "SUDO_UID="
          echo "SUDO_HOME="
        fi
        echo "USER=$(whoami)"
        echo "HOME=$HOME"
      register: user_info_output
      changed_when: false
      tags: [always]
    
    - name: Parse user info
      ansible.builtin.set_fact:
        parsed_user_info: "{{ dict(user_info_output.stdout_lines | map('regex_replace', '^([^=]+)=(.*)$', '\\1:\\2') | map('split', ':') | list) }}"
      tags: [always]
    
    - name: Set user facts
      ansible.builtin.set_fact:
        is_root: "{{ parsed_user_info.EUID == '0' }}"
        actual_user: "{{ parsed_user_info.SUDO_USER | default(parsed_user_info.USER) }}"
        user_home: "{{ parsed_user_info.SUDO_HOME | default(parsed_user_info.HOME) }}"
      tags: [always]
    
    - name: Debug user detection
      ansible.builtin.debug:
        msg: |
          User detection results:
          - Effective UID: {{ parsed_user_info.EUID }}
          - Running as root: {{ is_root }}
          - Original user: {{ actual_user }}
          - User home: {{ user_home }}
      tags: [always]

    # Skip credential setup if running as root directly (not via sudo)
    - name: Skip credential setup if running as root directly
      ansible.builtin.set_fact:
        skip_credential_setup: "{{ ansible_user_id == 'root' and lookup('env', 'SUDO_USER') == '' }}"
      tags: [always]

    - name: Show credential setup status
      ansible.builtin.debug:
        msg: "{{ skip_credential_setup | ternary('Running as direct root user - skipping credential setup', 'Setting up credentials for user ' + actual_user) }}"
      tags: [always]

    # Only run credential setup if not skipping
    - name: Setup user credentials
      when: not skip_credential_setup
      block:
        - name: Ensure ansible vars directory exists in user's home
          ansible.builtin.file:
            path: "{{ user_home }}/.ansible/vars"
            state: directory
            mode: '0700'
          tags: [setup, credential_setup]
    
        - name: Check if credentials file exists
          ansible.builtin.stat:
            path: "{{ user_home }}/.ansible/vars/config"
          register: config_file
          tags: [always]
    
        - name: Set first run flag 
          ansible.builtin.set_fact:
            first_run: "{{ not config_file.stat.exists }}"
          tags: [always]
    
        - name: Load stored credentials if they exist
          ansible.builtin.include_vars:
            file: "{{ user_home }}/.ansible/vars/config"
            name: stored_credentials
          when: config_file.stat.exists
          tags: [always]
    
        - name: Request credentials if needed
          block:
            - name: Collect Red Hat CDN username
              ansible.builtin.pause:
                prompt: "Enter your Red Hat CDN username"
                echo: true
              register: rh_username_input
              when: stored_credentials is not defined or stored_credentials.rh_username is not defined
              
            - name: Collect Red Hat CDN password
              ansible.builtin.pause:
                prompt: "Enter your Red Hat CDN password"
                echo: false
              register: rh_password_input
              when: stored_credentials is not defined or stored_credentials.rh_password is not defined
              
            - name: Collect Automation Hub token
              ansible.builtin.pause:
                prompt: "Enter your Automation Hub token (or press enter to skip)"
                echo: false
              register: automation_hub_token_input
              when: stored_credentials is not defined or stored_credentials.automation_hub_token is not defined
              
            - name: Collect Galaxy token
              ansible.builtin.pause:
                prompt: "Enter your Galaxy token (or press enter to skip)"
                echo: false
              register: galaxy_token_input
              when: stored_credentials is not defined or stored_credentials.galaxy_token is not defined
              
            - name: Set collected credential facts
              ansible.builtin.set_fact:
                rh_username: "{{ rh_username_input.user_input | default(stored_credentials.rh_username | default('')) }}"
                rh_password: "{{ rh_password_input.user_input | default(stored_credentials.rh_password | default('')) }}"
                automation_hub_token: "{{ automation_hub_token_input.user_input | default(stored_credentials.automation_hub_token | default('')) }}"
                galaxy_token: "{{ galaxy_token_input.user_input | default(stored_credentials.galaxy_token | default('')) }}"
              no_log: true
              
            - name: Create credentials file
              ansible.builtin.copy:
                dest: "{{ user_home }}/.ansible/vars/config"
                content: |
                  ---
                  # Ansible EE Builder Configuration - Last updated {{ ansible_date_time.iso8601 }}
                  rh_username: '{{ rh_username }}'
                  rh_password: '{{ rh_password }}'
                  automation_hub_token: '{{ automation_hub_token }}'
                  galaxy_token: '{{ galaxy_token }}'
                mode: '0600'
                # Remove owner and group attributes when running as root
              no_log: true
              
            - name: Set proper ownership on credentials file when needed
              ansible.builtin.file:
                path: "{{ user_home }}/.ansible/vars/config"
                owner: "{{ actual_user }}"
                group: "{{ actual_user }}"
                mode: '0600'
              when: actual_user != 'root' and actual_user != ''
              no_log: true
              
            - name: Report stored credentials
              ansible.builtin.debug:
                msg: |
                  ┌────────────────────────────────────────────────────────────────┐
                  │                  CREDENTIALS STORED                            │
                  ├────────────────────────────────────────────────────────────────┤
                  │ Credentials have been stored at: {{ user_home }}/.ansible/vars/config │
                  │ These will be used for future runs.                            │
                  └────────────────────────────────────────────────────────────────┘
          when: first_run or (stored_credentials is not defined)
          tags: [always]
    
    - name: Fail if not running with sudo
      ansible.builtin.fail:
        msg: |
          This playbook must be run as root or with sudo privileges for full functionality.
          
          For a full run to build environments, use:
            sudo ansible-playbook Ansible_Automation_Platform-ee_builder.yml -K
      when: not is_root
      tags: [always]
      
    - name: Show run mode
      ansible.builtin.debug:
        msg: |
          ┌────────────────────────────────────────────────────────────────────┐
          │                     RUN MODE INFORMATION                           │
          ├────────────────────────────────────────────────────────────────────┤
          │ {{ "FIRST RUN DETECTED: Running full setup" if first_run|default(false) else "SUBSEQUENT RUN: Using stored configuration" }} │
          │                                                                    │
          │ User: {{ actual_user }}                                            │
          │ Credentials: {{ "New" if first_run|default(false) else "Loaded from file" }}      │
          └────────────────────────────────────────────────────────────────────┘
      tags: [always]

    # Use sudo_user's home directory for config in the main play
    - name: Set config path for main play
      ansible.builtin.set_fact:
        config_path: "{{ user_home }}/.ansible/vars/config"
      tags: [always]

# Play 2: Display title and introduction
- name: Display title screen
  hosts: localhost
  connection: local
  gather_facts: false
  environment:
    ANSIBLE_LOCALHOST_WARNING: "False" 
    ANSIBLE_DEPRECATION_WARNINGS: "False"
    ANSIBLE_COMMAND_WARNINGS: "False"
    ANSIBLE_SYSTEM_WARNINGS: "False"
  tasks:
    - name: Clear screen before showing title
      ansible.builtin.shell: clear
      changed_when: false
      
    - name: Show title
      ansible.builtin.debug:
        msg: |
          ┌──────────────────────────────────────────────────────────────────────────────────────────────────────────────┐
          │                                                                                      ..:-=@@@@=-:..          │
          │                                                                                    .*%@@@@@@@@@@@@%*.        │
          │                                                                                 .:@@@@@@@@@@@@@@@@@@@@:.     │
          │                                                                                .*@@@@@@@@@@*-@@@@@@@@@@*.    │
          │                                                                               .@@@@@@@@@@@*. =@@@@@@@@@@@.   │
          │                                                                              .%@@@@@@@@@@@ .@ +@@@@@@@@@@%.  │
          │                                                                              -%@@@@@@@@@@..@%-.*@@@@@@@@@%-  │
          │     "A Streamlined Approach to Building Ansible Execution Environments"     .+@@@@@@@@@@= =@@@.:@@@@@@@@@@+. │
          │                                                                             .+@@@@@@@@@@ ..:+@%.-@@@@@@@@@+. │
          │                                                                             .=@@@@@@@@@ .@@+. *+.-@@@@@@@%=  │
          │                                                                              .%@@@@@@@:.*@@@@%.  .+@@@@@@%.  │
          │                                                                               .@@@@@@= =@@@@@@@%=.:%@@@@@.   │
          │                                                                                :%@@@@@@@@@@@@@@@@@@@@@@%:    │
          │                                                                                 .*@@@@@@@@@@@@@@@@@@@@*.     │
          │                                                                                   .+@@@@@@@@@@@@@@@@+..      │
          │                                                                                     ..+*%@@@@@@%*+..         │
          └──────────────────────────────────────────────────────────────────────────────────────────────────────────────┘
      tags: [always]

    - name: Pause for title screen
      ansible.builtin.pause:
        seconds: 3
        prompt: "Starting Execution Environment Builder..."
      tags: [always]

# Play 3: Main execution environment building process
- name: Build Execution Environments for Ansible Automation Platform
  hosts: localhost
  become: true
  gather_facts: true
  vars_files:
    - "{{ hostvars.localhost.config_path | default('~/.ansible/vars/config') }}"

  # Variables definition section remains the same
  vars:
    # Connection variables
    container_registries:
      - registry.redhat.io
      - console.redhat.com
      - registry.access.redhat.com
      - quay.io
      - registry.connect.redhat.com
    dns_servers:
      - '8.8.8.8'
      - '8.8.4.4'
    
    # Package and dependency variables
    required_packages:
      - python3-pip
      - ansible-builder
      - ansible-core
      - git
      - podman
      - podman-docker
      - tmux
      - xdg-utils
      - yum-utils
    
    # Always update the protected_images list in defaults/main.yml
    update_protected_list: true
    
    # Repository variables  
    git_repos:
      - url: 'https://github.com/cloin/ee-builds.git'
        dest: 'examples/ee-builds'
    work_dir: '/tmp/ee-containers'
    
    # Container image variables
    required_images:
      - registry.redhat.io/ansible-automation-platform-25/de-minimal-rhel8
      - registry.redhat.io/ansible-automation-platform-25/de-minimal-rhel9
      - registry.redhat.io/ansible-automation-platform-25/de-supported-rhel8
      - registry.redhat.io/ansible-automation-platform-25/de-supported-rhel9
      - registry.redhat.io/ansible-automation-platform-25/ee-minimal-rhel8
      - registry.redhat.io/ansible-automation-platform-25/ee-minimal-rhel9
      - registry.redhat.io/ansible-automation-platform-25/ee-supported-rhel8
      - registry.redhat.io/ansible-automation-platform-25/ee-supported-rhel9

  # Interactive variables - now using defaults from config file
  vars_prompt:
    - name: distribution_selection
      prompt: "Select distribution to build images for (8/9/both)"
      private: false
      default: "both"

  pre_tasks:
  
    - name: Check root status
      ansible.builtin.command: id -u
      register: user_id
      changed_when: false
      tags: [always]

    - name: Set root flag
      ansible.builtin.set_fact:
        is_root: "{{ user_id.stdout == '0' }}"
      tags: [always]

    - name: Warning if running as non-root
      ansible.builtin.debug:
        msg: |
          Running in LIMITED MODE as non-root user.
          Only setup tasks will be executed.
          For full functionality, run with sudo.
      when: not is_root
      tags: [always]

    # Rest of the tasks with proper conditional checks
    - name: Set Podman warning suppression environment variable
      ansible.builtin.set_fact:
        podman_env:
          PODMAN_IGNORE_CGROUPSV1_WARNING: "1"
      tags: [setup, env_config, podman_warnings]
      
    - name: Add Podman warning suppression to environment files
      ansible.builtin.lineinfile:
        path: "{{ item }}"
        regexp: '^export PODMAN_IGNORE_CGROUPSV1_WARNING='
        line: 'export PODMAN_IGNORE_CGROUPSV1_WARNING=1'
        create: true
        mode: '0644'
      with_items:
        - /etc/environment
        - /etc/profile.d/podman.sh
      when: is_root
      tags: [setup, env_config, podman_env_files]
      
    - name: Create systemd environment override for podman
      ansible.builtin.copy:
        content: |
          [Service]
          Environment=PODMAN_IGNORE_CGROUPSV1_WARNING=1
        dest: /etc/systemd/system/podman.service.d/environment.conf
        mode: '0644'
        create: true
      when: is_root
      
    - name: Reload systemd configuration
      ansible.builtin.systemd:
        daemon_reload: true
      when: is_root
    
    #
    # SECTION 1: Distribution Selection
    #
    - name: Process distribution selection
      ansible.builtin.set_fact:
        build_rhel8: "{{ distribution_selection == '8' or distribution_selection == 'both' }}"
        build_rhel9: "{{ distribution_selection == '9' or distribution_selection == 'both' }}"
      tags: [setup, distribution, dist_selection]
        
    - name: Show selected distributions
      ansible.builtin.debug:
        msg: "Building images for: {{ (build_rhel8 | bool) | ternary('RHEL 8', '') }}{{ (build_rhel8 and build_rhel9) | ternary(' and ', '') }}{{ (build_rhel9 | bool) | ternary('RHEL 9', '') }}"
      tags: [setup, distribution, dist_show_selected]
    
    - name: Filter required images based on distribution selection
      ansible.builtin.set_fact:
        filtered_images: >-
          {{
            (build_rhel8 | bool) | ternary(required_images | select('search', 'rhel8') | list, []) +
            (build_rhel9 | bool) | ternary(required_images | select('search', 'rhel9') | list, [])
          }}

    - name: Show filtered image list
      ansible.builtin.debug:
        msg: |
          Images selected for download:
          {% for image in filtered_images %}
          - {{ image }}
          {% endfor %}
      when: filtered_images | length > 0
        
    - name: Update required_images with filtered list
      ansible.builtin.set_fact:
        required_images: "{{ filtered_images }}"
      when: filtered_images is defined and filtered_images | length > 0

    #
    # SECTION 2: Base System Configuration
    #
    - name: Detect RHEL version
      ansible.builtin.set_fact:
        rhel_version: "{{ ansible_distribution_major_version | default('9') }}"
      tags: [setup, system_config, detect_rhel]
      
    - name: Enable required RHEL repositories based on version
      block:
        - name: Get list of available repositories
          ansible.builtin.shell: |
            if command -v subscription-manager >/dev/null 2>&1; then
              subscription-manager repos --list | grep "Repo ID" | awk '{print $3}'
            fi
          register: available_repos
          changed_when: false
          ignore_errors: true
          args:
            executable: /bin/bash

        - name: Show available repositories
          ansible.builtin.debug:
            msg: |
              Available repositories:
              {% for repo in available_repos.stdout_lines %}
              - {{ repo }}
              {% endfor %}
          when: available_repos.stdout_lines | length > 0

        - name: Define repository lists by RHEL version
          ansible.builtin.set_fact:
            rhel8_repos:
              - rhel-8-for-x86_64-baseos-rpms
              - rhel-8-for-x86_64-appstream-rpms
              - ansible-automation-platform-2.4-for-rhel-8-x86_64-rpms
              - rhel-8-for-x86_64-supplementary-rpms
              - codeready-builder-for-rhel-8-x86_64-rpms
            rhel9_repos:
              - rhel-9-for-x86_64-baseos-rpms
              - rhel-9-for-x86_64-appstream-rpms
              - ansible-automation-platform-2.4-for-rhel-9-x86_64-rpms
              - rhel-9-for-x86_64-supplementary-rpms
              - codeready-builder-for-rhel-9-x86_64-rpms

        - name: Select appropriate repositories based on detected RHEL version
          ansible.builtin.set_fact:
            repos_to_enable: "{{ (rhel_version == '8') | ternary(rhel8_repos, rhel9_repos) }}"

        - name: Enable only repositories that exist
          ansible.builtin.command:
            cmd: "subscription-manager repos --enable={{ item }}"
          loop: "{{ repos_to_enable | intersect(available_repos.stdout_lines) }}"
          register: repo_enable_result
          changed_when: repo_enable_result.rc == 0
          failed_when: false
      rescue:
        - name: Handle repository configuration failure
          ansible.builtin.debug:
            msg: "Warning: Unable to enable repositories. Continuing with available repositories."
      tags: [setup, system_config, repositories]

    #
    # SECTION 3: DNS and Network Setup
    #
    - name: Verify DNS resolution
      ansible.builtin.command:
        cmd: "nslookup {{ item }}"
      loop:
        - github.com
        - cdn-ubi.redhat.com
        - galaxy.ansible.com
      register: dns_checks
      changed_when: false
      failed_when: false
      loop_control:
        label: "{{ item }}"

    - name: Set DNS servers for Podman
      ansible.builtin.template:
        src: templates/registries.conf.j2
        dest: /etc/containers/registries.conf
        mode: '0644'
        backup: true
      when: is_root
      tags: [setup, network_config, dns_servers]

    #
    # SECTION 4: Podman Configuration Reset
    #
    - name: Complete Podman storage system reset
      block:
        - name: Show critical error message
          ansible.builtin.debug:
            msg: |
              Performing complete system reset of Podman storage.
              This will delete all local container images and data!

        - name: Stop all Podman processes
          ansible.builtin.shell: |
            # Kill all running containers
            podman ps -qa | xargs -r podman kill
            podman ps -qa | xargs -r podman rm -f
            
            # Stop podman service
            systemctl stop podman.service podman.socket || true
            
            # Kill any remaining podman processes
            pkill -9 podman || true
          changed_when: true
          ignore_errors: true
          
        - name: Safely clean container configuration
          block:
            - name: Get list of all existing tagged images
              ansible.builtin.shell: |
                podman images --format '{{ .Repository }}:{{ .Tag }}' | grep -v "<none>:<none>"
              register: existing_images
              changed_when: false
              
            - name: Create protected images list
              ansible.builtin.set_fact:
                protected_images: "{{ existing_images.stdout_lines | default([]) }}"
              
            - name: Display protected images
              ansible.builtin.debug:
                msg: |
                  Protected images that will NOT be removed:
                  {% for image in protected_images %}
                  - {{ image }}
                  {% endfor %}
            
            - name: Remove dangling containers safely
              ansible.builtin.shell: |
                # Only remove containers that are not using protected images
                for container in $(podman ps -a --format '{{ .ID }}'); do
                  image=$(podman inspect --format '{{ .Config.Image }}' $container)
                  if echo "$image" | grep -q "<none>" || ! echo "{{ protected_images | join(' ') }}" | grep -q "$image"; then
                    echo "Removing container $container with image $image"
                    podman rm -f $container
                  fi
                done
              changed_when: true
              
            - name: Remove only dangling images
              ansible.builtin.shell: |
                # Remove only <none>:<none> images
                podman images --filter "dangling=true" --format '{{ .ID }}' | xargs -r podman rmi -f
              changed_when: true
              
            - name: Clean unused volumes and networks only
              ansible.builtin.shell: |
                podman volume prune -f
                podman network prune -f
              changed_when: true
              
            - name: Clean temporary files
              ansible.builtin.shell: |
                # Remove only temporary build files
                rm -rf /tmp/ansible-builder.*
                rm -rf /tmp/pip-*
              changed_when: true
          ignore_errors: true
          
        - name: Create basic container configuration files
          ansible.builtin.shell: |
            mkdir -p /etc/containers/containers.conf.d
            mkdir -p /etc/containers/storage.conf.d
            
            # Create base storage configuration
            cat > /etc/containers/storage.conf << EOF
            [storage]
            driver = "overlay"
            runroot = "/run/containers/storage"
            graphroot = "/var/lib/containers/storage"
            
            [storage.options]
            additionalimagestores = []
            
            [storage.options.overlay]
            mountopt = "nodev,metacopy=on"
            mount_program = "/usr/bin/fuse-overlayfs"
            ignore_chown_errors = "false"
            EOF
            
            # Create minimal registries configuration
            cat > /etc/containers/registries.conf << EOF
            [registries.search]
            registries = ['docker.io', 'registry.fedoraproject.org', 'registry.access.redhat.com', 'quay.io']
            
            [registries.insecure]
            registries = []
            
            [registries.block]
            registries = []
            EOF
          changed_when: true
          ignore_errors: true
          
        - name: Create container directory structure from scratch
          ansible.builtin.shell: |
            # Create essential directories with proper permissions
            mkdir -p /var/lib/containers/storage/overlay
            mkdir -p /var/lib/containers/storage/overlay-layers
            mkdir -p /var/lib/containers/storage/overlay-images
            mkdir -p /var/lib/containers/storage/vfs
            mkdir -p /var/lib/containers/storage/vfs-containers
            mkdir -p /var/lib/containers/storage/vfs-images
            mkdir -p /var/lib/containers/storage/vfs-layers
            mkdir -p /run/containers/storage
            
            # Set proper ownership
            chown -R root:root /var/lib/containers
            chown -R root:root /run/containers
          changed_when: true
          
        - name: Export environment variables to disable warnings
          ansible.builtin.shell: |
            # Add to environment
            export PODMAN_IGNORE_CGROUPSV1_WARNING=1
            
            # Add to current shell and .bashrc
            echo 'export PODMAN_IGNORE_CGROUPSV1_WARNING=1' >> ~/.bashrc
            
            # Create systemd override for podman service
            mkdir -p /etc/systemd/system/podman.service.d/
            cat > /etc/systemd/system/podman.service.d/environment.conf << EOF
            [Service]
            Environment=PODMAN_IGNORE_CGROUPSV1_WARNING=1
            EOF
            
            # Reload systemd to pick up changes
            systemctl daemon-reload
            systemctl restart podman.socket podman.service || true
          changed_when: true
      when: is_root
    
    #
    # SECTION 5: Registry Authentication
    #
    - name: Setup Red Hat registry authentication
      block:
        - name: Verify podman is working properly
          ansible.builtin.command:
            cmd: "podman info --format 'Driver: {{ '{{' }} .Store.GraphDriverName {{ '}}' }}'"
          environment:
            PODMAN_IGNORE_CGROUPSV1_WARNING: "1"
          register: podman_check
          failed_when: podman_check.rc != 0
        
        - name: Initialize registry login tracking
          ansible.builtin.set_fact:
            registry_login_success: false
            registry_login_results: {}
        
        - name: Login to container registries
          ansible.builtin.command:
            cmd: "podman login --username {{ rh_username }} --password {{ rh_password }} {{ item }}"
          environment: "{{ podman_env }}"
          no_log: true
          register: registry_logins
          changed_when: registry_logins.rc == 0
          failed_when: false
          loop: "{{ container_registries }}"
          loop_control:
            label: "{{ item }}"
          tags: [setup, registry, registry_login]
            
        - name: Process registry login results
          ansible.builtin.set_fact:
            registry_login_success: >-
              {{ registry_login_success or 
                 (item.item != 'quay.io' and item.rc == 0) }}
            registry_login_results: "{{ registry_login_results | combine({item.item: (item.rc == 0)}) }}"
          loop: "{{ registry_logins.results }}"
          loop_control:
            label: "{{ item.item }}"
            
        - name: Display registry login status
          ansible.builtin.debug:
            msg: |
              Registry Authentication Results:
              {% for registry, success in registry_login_results.items() %}
              - {{ registry }}: {{ 'SUCCESS' if success else 'FAILED' }}
              {% endfor %}
              
        - name: Fail if authentication failed for all critical registries
          ansible.builtin.fail:
            msg: |
              CRITICAL ERROR: Failed to authenticate with any required container registries.
              Authentication to at least one Red Hat registry is required for this playbook to function.
              Please check your Red Hat credentials and network connectivity.
          when: not registry_login_success

    #
    # SECTION 6: Builder Configuration
    #
    - name: Configure ansible-builder
      block:
        - name: Check if ansible-builder is already installed
          ansible.builtin.shell: which ansible-builder || echo "not found"
          register: ansible_builder_check
          changed_when: false

        - name: Install ansible-builder via pip if not found
          ansible.builtin.pip:
            name: ansible-builder
            state: present
            extra_args: "--user"
          when: "'not found' in ansible_builder_check.stdout"
          
        - name: Create ansible.cfg in build context
          ansible.builtin.template:
            src: templates/ansible.cfg.j2
            dest: "{{ work_dir }}/_build/configs/ansible.cfg"
            mode: '0644'
          vars:
            automation_hub_token: "{{ automation_hub_token | default('') }}"
            current_user: "{{ ansible_user_id | default('root') }}"
          tags: [setup, builder_config, ansible_cfg]

        - name: Copy ansible.cfg to system locations
          ansible.builtin.copy:
            src: "{{ work_dir }}/_build/configs/ansible.cfg"
            dest: "{{ item }}"
            mode: '0644'
            remote_src: true
          with_items:
            - /etc/ansible/ansible.cfg
            - "ansible.cfg"

    - name: Ensure ansible.cfg exists in current directory
      block:
        - name: Check if ansible.cfg exists in current directory
          ansible.builtin.stat:
            path: "{{ playbook_dir }}/ansible.cfg"
          register: ansible_cfg_check
          
        - name: Create ansible.cfg from template if it doesn't exist
          ansible.builtin.template:
            src: templates/ansible.cfg.j2
            dest: "{{ playbook_dir }}/ansible.cfg"
            mode: '0644'
          when: not ansible_cfg_check.stat.exists
          vars:
            automation_hub_token: "{{ automation_hub_token | default('') }}"
            
        - name: Ensure ansible.cfg has correct permissions
          ansible.builtin.file:
            path: "{{ playbook_dir }}/ansible.cfg"
            mode: '0644'
            owner: "{{ actual_user | default(ansible_user_id) }}"
            group: "{{ actual_user | default(ansible_user_id) }}"
          when: actual_user is defined and actual_user != ""
          failed_when: false
      tags: [setup, ansible_config, config_files]

    - name: Update ansible.cfg with token information
      block:
        - name: Apply token to ansible.cfg from template
          ansible.builtin.template:
            src: templates/ansible.cfg.j2
            dest: "{{ playbook_dir }}/ansible.cfg"
            mode: '0644'
          when: automation_hub_token is defined and automation_hub_token != ""
          vars:
            current_user: "{{ actual_user | default(ansible_user_id) }}"
            
        - name: Report ansible.cfg update
          ansible.builtin.debug:
            msg: "ansible.cfg has been updated with authentication tokens"
          when: automation_hub_token is defined and automation_hub_token != ""
      tags: [setup, ansible_config, config_files]

    #
    # SECTION 7: Image Management
    #
    - name: Check and pull required container images
      block:
        - name: Check if required container images exist
          ansible.builtin.command:
            cmd: "podman image exists {{ item }}"
          environment: "{{ podman_env }}"
          loop: "{{ required_images }}"
          register: image_check_results
          changed_when: false
          failed_when: false
          loop_control:
            label: "{{ item }}"
          tags: [setup, images, check_images]

        - name: Display missing images to pull
          ansible.builtin.set_fact:
            missing_images: "{{ image_check_results.results | selectattr('rc', 'defined') | selectattr('rc', 'ne', 0) | map(attribute='item') | list }}"
          tags: [setup, images, identify_missing]

        - name: Show missing image count
          ansible.builtin.debug:
            msg: "Found {{ missing_images | length }} images that need to be pulled"
          tags: [setup, images, count_missing]

        # Skip subsequent tasks if no images are missing
        - name: Skip message when no images need to be pulled
          ansible.builtin.debug:
            msg: "All required images already present, skipping pull operations"
          when: missing_images | length == 0
          tags: [setup, images, skip_message]

        # Only run these tasks when images need to be pulled
        - name: Handle missing images
          when: missing_images | length > 0
          block:
            - name: Pull missing container images
              ansible.builtin.command:
                cmd: "podman pull {{ item }}"
              environment: "{{ podman_env }}"
              loop: "{{ missing_images }}"
              register: pull_results
              changed_when: pull_results.rc == 0
              failed_when: false
              retries: 3
              delay: 5
              until: pull_results is succeeded
              loop_control:
                label: "{{ item }}"
                pause: 1.0
              tags: [setup, images, pull_images]

            - name: Process image pull results
              ansible.builtin.set_fact:
                successful_pulls: "{{ pull_results.results | default([]) | selectattr('rc', 'defined') | selectattr('rc', 'eq', 0) | list }}"
                failed_pulls: "{{ pull_results.results | default([]) | selectattr('rc', 'defined') | selectattr('rc', 'ne', 0) | list }}"
              tags: [setup, images, process_results]

            - name: Summarize image pull results
              ansible.builtin.debug:
                msg: |
                  Image Pull Summary:
                  ───────────────────────────
                  Successfully pulled images:
                  {% for image in successful_pulls | default([]) %}
                  - {{ image }}
                  {% endfor %}
                  
                  Failed to pull images:
                  {% for image in failed_pulls | default([]) %}
                  - {{ image }}
                  {% endfor %}
              tags: [setup, images, summarize]

            - name: Fail if any required images could not be pulled
              ansible.builtin.fail:
                msg: |
                  CRITICAL ERROR: Failed to pull the following required images:
                  {% for image in failed_pulls | default([]) %}
                  - {{ image }}
                  {% endfor %}
                  
                  These images are required for execution environment building.
                  Please check your network connection, registry authentication,
                  and ensure these images are accessible.
              when: failed_pulls is defined and failed_pulls | length > 0
              tags: [setup, images, validation]
          tags: [setup, images, pull_process]
      rescue:
        - name: Critical failure in image pulling
          ansible.builtin.fail:
            msg: |
              CRITICAL ERROR: Failed to pull required container images.
              This playbook cannot continue without the necessary base images.
              
              Please verify:
              1. Registry authentication is working (podman login)
              2. Network connectivity to container registries
              3. The required images exist and are accessible
      tags: [setup, images]

    #
    # SECTION 8: Dependencies Management
    #
    - name: Manage dependencies
      block:
        - name: Check if requirements.txt exists
          ansible.builtin.stat:
            path: "{{ work_dir }}/files/requirements.txt"
          register: requirements_txt

        - name: Install Python packages from requirements.txt
          ansible.builtin.pip:
            requirements: "{{ work_dir }}/files/requirements.txt"
            extra_args: "--upgrade"
          when: requirements_txt.stat.exists
          register: pip_install_result
          retries: 2
          delay: 3
          until: pip_install_result is succeeded
          failed_when: false

        - name: Check if requirements.yml exists
          ansible.builtin.stat:
            path: "{{ work_dir }}/files/requirements.yml"
          register: requirements_yml

        - name: Install ansible-galaxy collections
          ansible.builtin.command:
            cmd: ansible-galaxy collection install -r {{ work_dir }}/files/requirements.yml
          when: requirements_yml.stat.exists
          register: galaxy_install_result
          changed_when: galaxy_install_result.rc == 0
          failed_when: galaxy_install_result.rc != 0
          ignore_errors: true

    # 
    # SECTION 8.5: Environment Selection Filtering
    #
    - name: Filter available environments based on distribution selection
      block:
        - name: Get all available environments
          ansible.builtin.find:
            paths: "{{ work_dir }}/environments"
            file_type: directory
          register: all_environments
          
        - name: Process environments for filtering
          ansible.builtin.set_fact:
            rhel8_environments: "{{ all_environments.files | selectattr('path', 'search', 'rhel8') | map(attribute='path') | list }}"
            rhel9_environments: "{{ all_environments.files | selectattr('path', 'search', 'rhel9') | map(attribute='path') | list }}"
            neutral_environments: "{{ all_environments.files | rejectattr('path', 'search', 'rhel[89]') | map(attribute='path') | list }}"
            
        - name: Set available environments based on distribution selection
          ansible.builtin.set_fact:
            available_environments: "{{ 
                neutral_environments + 
                (build_rhel8 | bool) | ternary(rhel8_environments, []) + 
                (build_rhel9 | bool) | ternary(rhel9_environments, [])
              }}"
              
        - name: Debug available environments
          ansible.builtin.debug:
            msg: "Available environments based on distribution selection: {{ available_environments | map('basename') | list }}"
            
        # Pass the filtered environment list to the environment_menu.yml
        - name: Set environment_paths for menu
          ansible.builtin.set_fact:
            environment_paths: "{{ available_environments }}"
      when: build_rhel8 is defined or build_rhel9 is defined

    # 
    # Continue with environment selection, monitoring setup, etc.
    #
    - name: Include environment menu tasks
      ansible.builtin.include_tasks: tasks/environment_menu.yml
      register: environment_menu_result
      tags: [environment, menu, env_selection]

    - name: Debug selected environments
      ansible.builtin.debug:
        msg: "Selected environments to process: {{ selected_environments | join(', ') }}"
      when: selected_environments | default([]) | length > 0
      
    # SECTION 8: Monitoring Setup
    #
    - name: Setup basic podman monitoring
      block:
        - name: Ensure scripts directory exists
          ansible.builtin.file:
            path: "scripts"
            state: directory
            mode: '0755'
          tags: [monitoring, monitoring_dir]

        - name: Create monitoring script
          ansible.builtin.copy:
            dest: "scripts/start_monitor.sh"
            mode: '0755'
            content: |
              #!/bin/bash
              # Enhanced monitoring script for podman with auto-popup terminal and title screen

              # Kill any existing session
              tmux kill-session -t podman-monitor 2>/dev/null || true
              
              # Create the basic session
              tmux new-session -d -s podman-monitor
              
              # Configure the session with proper formatting
              tmux set -g status-style bg=black,fg=white
              tmux set -g default-terminal "screen-256color"
              tmux set -g terminal-overrides ",xterm-256color:Tc"
              
              # Set larger history limit for better scrollback
              tmux set -g history-limit 10000
              
              # Split into 2 panes
              tmux split-window -v -p 30
              
              # Put commands in each pane
              tmux select-pane -t 0
              
              # Clear screen and display tmux_header.txt as main title
              tmux send-keys "clear" C-m
              
              # Display the header file directly in the main pane
              if [ -f "tmux_header.txt" ]; then
                # Display the header with proper coloring
                tmux send-keys "cat tmux_header.txt" C-m
              else
                # Fallback if header file isn't found
                tmux send-keys "printf '\e[1;36m%s\e[0m\n' '=== BUILD OUTPUT ==='" C-m
                tmux send-keys "echo 'Waiting for builds to start...'" C-m
              fi

              # Configure second pane
              tmux select-pane -t 1
              tmux send-keys "printf '\e[1;32m%s\e[0m\n' '=== IMAGES ==='" C-m
              tmux send-keys "watch -n .5 'podman images'" C-m
              
              # Return to main pane
              tmux select-pane -t 0

              # Auto-open terminal with tmux session attached
              function open_terminal_with_tmux {
                # If we're already in tmux, create a new window
                if [ -n "$TMUX" ]; then
                  tmux new-window "tmux attach -t podman-monitor"
                  return 0
                fi
                
                # Try different terminal emulators
                for terminal in gnome-terminal konsole xfce4-terminal terminator mate-terminal x-terminal-emulator xterm; do
                  if command -v $terminal >/dev/null 2>&1; then
                    case $terminal in
                      gnome-terminal)
                        nohup $terminal --geometry=120x40 -- tmux attach -t podman-monitor >/dev/null 2>&1 &
                        ;;
                      konsole|xfce4-terminal|terminator|mate-terminal|x-terminal-emulator)
                        nohup $terminal --geometry=120x40 -e "tmux attach -t podman-monitor" >/dev/null 2>&1 &
                        ;;
                      xterm)
                        nohup $terminal -geometry 120x40 -e "tmux attach -t podman-monitor" >/dev/null 2>&1 &
                        ;;
                    esac
                    echo "Opened monitoring in $terminal"
                    return 0
                  fi
                done
                
                # WSL-specific handling
                if (grep -q Microsoft /proc/version 2>/dev/null); then
                  nohup cmd.exe /c start wt.exe -w 0 new-tab --title "Podman Monitor" bash -c "tmux attach -t podman-monitor" >/dev/null 2>&1 &
                  if [ $? -eq 0 ]; then
                    echo "Opened monitoring in Windows Terminal"
                    return 0
                  fi
                fi
                
                return 1
              }

              # Try to open terminal with tmux
              if ! open_terminal_with_tmux; then
                echo "Could not automatically open a terminal. Connect with: tmux attach -t podman-monitor"
              fi
          tags: [monitoring, monitoring_create_script]

        - name: Run monitoring script
          ansible.builtin.command: "scripts/start_monitor.sh"
          changed_when: true
          tags: [monitoring, monitoring_start]

        - name: Display monitoring instructions
          ansible.builtin.debug:
            msg: |
              ┌────────────────────────────────────────────────────────────────┐
              │                  BUILD MONITORING AVAILABLE                    │
              ├────────────────────────────────────────────────────────────────┤
              │ To monitor build progress, run:                                │
              │   tmux attach -t podman-monitor                                │
              └────────────────────────────────────────────────────────────────┘
          tags: [monitoring, monitoring_instructions]
      tags: [monitoring]

    - name: Set build_ready flag
      ansible.builtin.set_fact:
        build_ready: "{{ selected_environments | default([]) | length > 0 }}"
      tags: [build, build_set_ready_flag]

    - name: Build execution environments
      block:
        - name: Skip message if environment is not compatible with selected distributions
          ansible.builtin.debug:
            msg: "Skipping environment '{{ item }}' as it's not compatible with selected distributions."
          loop: "{{ selected_environments | default([]) }}"
          when: >
            (not build_rhel8 and 'rhel8' in item) or
            (not build_rhel9 and 'rhel9' in item)
          loop_control:
            label: "{{ item }}"
          tags: [build, build_process, skip_incompatible]
            
        - name: Build compatible selected environments
          include_tasks: tasks/build_environment.yml
          vars:
            current_env: "{{ item }}"  # Set current_env to the environment name
            environment_dir: "{{ work_dir }}/environments/{{ item }}"  # Add this missing variable
          loop: "{{ selected_environments }}"
          when: >
            (build_rhel8 and 'rhel8' in item) or
            (build_rhel9 and 'rhel9' in item) or
            ('rhel8' not in item and 'rhel9' not in item)
          loop_control:
            label: "{{ item }}"
          tags: [build, build_process, execute_environment]
          
        - name: Fix systemd-python dependency in requirements.txt
          ansible.builtin.replace:
            path: "environments/{{ current_env }}/requirements.txt"
            regexp: '^systemd-python.*$'
            replace: "# systemd-python was causing build failures - disabled\n# systemd-python; sys_platform == 'linux' and 'linux' in platform_machine"
          when: "'rhel9' in current_env"
          ignore_errors: true
          tags: [build, build_deps]
          
        - name: Remove temporary build files
          ansible.builtin.shell: |
            # Remove only build-related temporary files
            rm -rf /tmp/ansible-builder.*
            rm -rf /tmp/pip-*
            
            # Clean up dangling containers from failed build only
            podman ps -a --filter "name={{ current_env }}" --format "{{.ID}}" | xargs -r podman rm -f
            
            # Clean up only dangling images (untagged)
            podman images --filter "dangling=true" --format "{{.ID}}" | xargs -r podman rmi -f
            
            # Don't use podman system prune as it's too aggressive
            # Instead clean only build-related volumes
            podman volume ls --filter "label=io.buildah.volume=builder" --format "{{.Name}}" | xargs -r podman volume rm
            
            echo "Cleaned up build artifacts for {{ current_env }}"
          changed_when: true
          ignore_errors: true
      when: is_root and build_ready | default(false) | bool
      tags: [build]

    #
    # SECTION 10: Create Sample Environments
    #
    - name: Check for existing environments
      ansible.builtin.find:
        paths: "{{ work_dir }}/environments"
        file_type: directory
      register: existing_env_dirs
      
    - name: Create sample environment directories with clear RHEL version indicators
      ansible.builtin.file:
        path: "{{ work_dir }}/environments/{{ item }}"
        state: directory
        mode: '0755'
      with_items:
        - "rhel8"
        - "rhel9"
      when: existing_env_dirs.files | length == 0

    #
    # SECTION 11: Environment Filtering and Selection
    #
    - name: Filter available environments based on distribution selection
      block:
        - name: Get all available environments
          ansible.builtin.find:
            paths: "{{ work_dir }}/environments"
            file_type: directory
          register: all_environments
          
        - name: Display all discovered environments before filtering
          ansible.builtin.debug:
            msg: |
              All available environments before filtering:
              {% for env in all_environments.files %}
              - {{ env.path | basename }}
              {% endfor %}
        
        - name: Process environments for filtering
          ansible.builtin.set_fact:
            rhel8_environments: "{{ all_environments.files | selectattr('path', 'search', 'rhel8') | map(attribute='path') | list }}"
            rhel9_environments: "{{ all_environments.files | selectattr('path', 'search', 'rhel9') | map(attribute='path') | list }}"
            neutral_environments: "{{ all_environments.files | rejectattr('path', 'search', 'rhel[89]') | map(attribute='path') | list }}"

        - name: Display filtered environment lists
          ansible.builtin.debug:
            msg: |
              RHEL 8 environments: {{ rhel8_environments | map('basename') | list }}
              RHEL 9 environments: {{ rhel9_environments | map('basename') | list }}
              Neutral environments: {{ neutral_environments | map('basename') | list }}
            
        - name: Set available environments based on distribution selection
          ansible.builtin.set_fact:
            available_environments: "{{ 
                neutral_environments + 
                (build_rhel8 | bool) | ternary(rhel8_environments, []) + 
                (build_rhel9 | bool) | ternary(rhel9_environments, [])
              }}"
            environment_paths: "{{ 
                neutral_environments + 
                (build_rhel8 | bool) | ternary(rhel8_environments, []) + 
                (build_rhel9 | bool) | ternary(rhel9_environments, [])
              }}"
              
        - name: Display final filtered environment list
          ansible.builtin.debug:
            msg: |
              Final environment list for {{ (build_rhel8 | bool) | ternary('RHEL 8', '') }}{{ (build_rhel8 and build_rhel9) | ternary(' and ', '') }}{{ (build_rhel9 | bool) | ternary('RHEL 9', '') }}:
              {{ environment_paths | map('basename') | list }}

    - name: Build summary report
      ansible.builtin.debug:
        msg: |
          ====================================================
                         BUILD SUMMARY REPORT
          ====================================================
          
          Total environments processed: {{ selected_environments | length }}
          
          {% if failed_environments | default([]) | length > 0 %}
          FAILED ENVIRONMENTS:
          {% for env in failed_environments | default([]) %}
          ✗ {{ env }}
          {% endfor %}
          
          These environments were skipped due to build failures.
          Check logs in /var/log/ansible/ansible-builder/ for details.
          {% else %}
          All builds completed successfully!
          {% endif %}
      run_once: true
      tags: [build, summary]

    - name: Update protected images list
      block:
        - name: Get all tagged images
          ansible.builtin.shell: |
            podman images --format '{% raw %}{{ .Repository }}:{{ .Tag }}{% endraw %}' | grep -v "<none>:<none>"
          register: current_images
          changed_when: false
          
        - name: Read existing protected_images file if it exists
          ansible.builtin.slurp:
            src: "{{ playbook_dir }}/protected_images.yml"
          register: existing_protected_file
          ignore_errors: true
          
        - name: Parse existing protected images
          ansible.builtin.set_fact:
            existing_protected: "{{ (existing_protected_file.content | b64decode | from_yaml).protected_images | default([]) }}"
          when: existing_protected_file is succeeded
          
        - name: Combine all protected images
          ansible.builtin.set_fact:
            consolidated_images: "{{ (existing_protected | default([])) + current_images.stdout_lines | unique }}"
          
        - name: Update protected_images.yml
          ansible.builtin.template:
            src: templates/protected_images.j2
            dest: "{{ playbook_dir }}/protected_images.yml"
            mode: '0644'
      tags: [setup, images, protect_images, token_refresh, cron]

    - name: Create cron job to refresh the token every 2 weeks
      ansible.builtin.cron:
        name: "Refresh Red Hat Automation Hub token"
        user: "{{ actual_user }}"
        minute: "0"
        hour: "4"
        day: "*/14"
        job: "{{ playbook_dir }}/scripts/refresh_rh_token.sh > /dev/null 2>&1"
      ignore_errors: true

    - name: Verify Automation Hub token
      block:
        - name: Test Automation Hub token validity
          ansible.builtin.uri:
            url: https://console.redhat.com/api/automation-hub/api/v3/collections/
            method: GET
            headers:
              Authorization: "Bearer {{ automation_hub_token | default('') }}"
          register: token_check
          failed_when: false
          
        - name: Get new token if current one is invalid
          block:
            - name: Display token renewal instructions
              ansible.builtin.pause:
                prompt: |
                  ⚠️  Your Automation Hub token is invalid or has expired!
                  
                  Please follow these steps:
                  1. Go to: https://console.redhat.com/ansible/automation-hub/token
                  2. Click the blue "Load Token" button
                  3. Copy the generated offline token
                  4. Paste it below
                  
                  Enter your new token
              register: new_token_input
              when: token_check.status is defined and token_check.status != 200
              
            - name: Set new token value
              ansible.builtin.set_fact:
                automation_hub_token: "{{ new_token_input.user_input }}"
              when: new_token_input is defined and new_token_input.user_input is defined

            - name: Verify new token
              ansible.builtin.uri:
                url: https://console.redhat.com/api/automation-hub/api/v3/collections/
                method: GET
                headers:
                  Authorization: "Bearer {{ automation_hub_token | default('') }}"
              register: new_token_check
              failed_when: false
              when: new_token_input is defined and new_token_input.user_input is defined

            - name: Handle still invalid token
              ansible.builtin.fail:
                msg: |
                  The new token appears to be invalid.
                  
                  Please double check:
                  1. That you copied the entire token string correctly
                  2. Your network connectivity to console.redhat.com
                  3. That your Red Hat account has appropriate permissions
          when: token_check.status is defined and token_check.status != 200
          
        - name: Save valid token to ansible.cfg
          ansible.builtin.template:
            src: templates/ansible.cfg.j2
            dest: "{{ playbook_dir }}/ansible.cfg"
            mode: '0644'
          when: automation_hub_token is defined and automation_hub_token != ""
      tags: [setup, token_validation]

    - name: Create token refresh automation
      block:
        - name: Create token refresh script directory
          ansible.builtin.file:
            path: "{{ playbook_dir }}/scripts"
            state: directory
            mode: '0755'

        - name: Create token refresh script
          ansible.builtin.template:
            dest: "{{ playbook_dir }}/scripts/refresh_rh_token.sh"
            mode: '0700'
            content: |
              #!/bin/bash
              
              # Set up logging
              LOG_FILE="{{ user_home }}/.ansible/vars/token_refresh.log"
              CONFIG_PATH="{{ user_home }}/.ansible/vars/config"
              
              # Log start time
              echo "===== Token refresh attempt started at $(date) =====" >> $LOG_FILE
              
              # Extract the refresh token from config
              if [ -f "$CONFIG_PATH" ]; then
                # Extract refresh token from the config file
                REFRESH_TOKEN=$(grep "automation_hub_token" "$CONFIG_PATH" | head -1 | cut -d "'" -f 4)
                
                # Check if token is available
                if [ -z "$REFRESH_TOKEN" ]; then
                  echo "ERROR: Could not find refresh token in $CONFIG_PATH" >> $LOG_FILE
                  exit 1
                fi
                
                # Attempt to refresh the token
                echo "Refreshing token..." >> $LOG_FILE
                RESPONSE=$(curl https://sso.redhat.com/auth/realms/redhat-external/protocol/openid-connect/token \
                  -d grant_type=refresh_token \
                  -d client_id="cloud-services" \
                  -d refresh_token="$REFRESH_TOKEN" \
                  --fail \
                  --silent \
                  --show-error 2>&1)
                
                # Check result
                if [ $? -eq 0 ]; then
                  echo "SUCCESS: Token refresh completed successfully" >> $LOG_FILE
                  
                  # Extract and update new token
                  NEW_TOKEN=$(echo $RESPONSE | jq -r '.refresh_token')
                  if [ "$NEW_TOKEN" != "null" ] && [ -n "$NEW_TOKEN" ]; then
                    # Create a backup of the config
                    cp "$CONFIG_PATH" "${CONFIG_PATH}.bak"
                    
                    # Replace the token in the config file
                    sed -i "s|automation_hub_token: '$REFRESH_TOKEN'|automation_hub_token: '$NEW_TOKEN'|g" "$CONFIG_PATH"
                    echo "Token updated in config file" >> $LOG_FILE
                  else
                    echo "WARNING: Response didn't contain a valid refresh token" >> $LOG_FILE
                  fi
                else
                  echo "ERROR: Token refresh failed" >> $LOG_FILE
                  echo "Response: $RESPONSE" >> $LOG_FILE
                fi
              else
                echo "ERROR: Config file not found at $CONFIG_PATH" >> $LOG_FILE
              fi
              
              echo "===== Token refresh attempt completed at $(date) =====" >> $LOG_FILE
              echo "" >> $LOG_FILE

        - name: Install jq for JSON parsing
          ansible.builtin.package:
            name: jq
            state: present
          ignore_errors: true

        - name: Create cron job to refresh the token every 2 weeks
          ansible.builtin.cron:
            name: "Refresh Red Hat Automation Hub token"
            job: "{{ playbook_dir }}/scripts/refresh_rh_token.sh > /dev/null 2>&1"
            minute: "0"
            hour: "4"
            day: "*/14"
            user: "{{ actual_user }}"
            
      tags: [setup, token_refresh, cron]


